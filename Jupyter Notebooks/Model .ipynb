{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook pre-processed data and trains different machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Url</th>\n",
       "      <th>Content</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A polite request to all Indians here</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2ct57...</td>\n",
       "      <td>I don't know if it is the same situation in ot...</td>\n",
       "      <td>Our society thrives on abuse of power. We let...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pitting a community against a political party ...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/futac9...</td>\n",
       "      <td>First of all let me start by saying it was stu...</td>\n",
       "      <td>Our country is just too far in at the moment ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A new political party gave a full front page a...</td>\n",
       "      <td>https://i.redd.it/yjo9wpy38el41.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This looks like an IIPM ad 1. Where did they ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hit by backlash over posts on lack of medical ...</td>\n",
       "      <td>https://theprint.in/india/hit-by-backlash-over...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Well, Some people really deserve to die. ~~/s...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics in the time of corona: WB CM question...</td>\n",
       "      <td>https://www.timesnownews.com/india/article/pol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh FFS. \\n\\nYellow, Orange, Green, Red, all a...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0               A polite request to all Indians here   \n",
       "1  Pitting a community against a political party ...   \n",
       "2  A new political party gave a full front page a...   \n",
       "3  Hit by backlash over posts on lack of medical ...   \n",
       "4  Politics in the time of corona: WB CM question...   \n",
       "\n",
       "                                                 Url  \\\n",
       "0  https://www.reddit.com/r/india/comments/g2ct57...   \n",
       "1  https://www.reddit.com/r/india/comments/futac9...   \n",
       "2                https://i.redd.it/yjo9wpy38el41.jpg   \n",
       "3  https://theprint.in/india/hit-by-backlash-over...   \n",
       "4  https://www.timesnownews.com/india/article/pol...   \n",
       "\n",
       "                                             Content  \\\n",
       "0  I don't know if it is the same situation in ot...   \n",
       "1  First of all let me start by saying it was stu...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Comments     Flair  \n",
       "0   Our society thrives on abuse of power. We let...  Politics  \n",
       "1   Our country is just too far in at the moment ...  Politics  \n",
       "2   This looks like an IIPM ad 1. Where did they ...  Politics  \n",
       "3   Well, Some people really deserve to die. ~~/s...  Politics  \n",
       "4   Oh FFS. \\n\\nYellow, Orange, Green, Red, all a...  Politics  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('morefeaturesDataset.csv')\n",
    "dataset = dataset.drop(columns=['ID'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shreya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing HTML syntaxes\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# removing punctuation marks\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Removing stop-words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(rawText):\n",
    "    \"\"\"\n",
    "    This function takes a raw string review as input, and applies the following steps to return a refined string review as output:\n",
    "    1. removing HTML tags\n",
    "    2. removing punctuation marks\n",
    "    3. converting the text to lower case\n",
    "    4. splitting the string into words\n",
    "    5. removing stop words\n",
    "    \"\"\"\n",
    "    # remove HTML tags\n",
    "    noHtml = bs(rawText, \"lxml\").get_text()\n",
    "    \n",
    "    #remove punctuation marks\n",
    "    letters_only = re.sub(\"[^a-zA-Z ]\", \"\", noHtml)\n",
    "    \n",
    "    #convert to lower case\n",
    "    tolower = letters_only.lower()\n",
    "    \n",
    "    #split\n",
    "    words = tolower.split()\n",
    "    \n",
    "    #convert stopwords list to set for fast searching\n",
    "    stopwordsSet = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    #remove stop words\n",
    "    RefinedWords = [w for w in words if w not in stopwordsSet]\n",
    "    \n",
    "    #form new review\n",
    "    return(\" \".join(RefinedWords) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Url</th>\n",
       "      <th>Content</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polite request indians</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2ct57...</td>\n",
       "      <td>dont know situation countries india seen lot o...</td>\n",
       "      <td>society thrives abuse power let many idiots ab...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pitting community political party fucking stupid</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/futac9...</td>\n",
       "      <td>first let start saying stupid whatever muslims...</td>\n",
       "      <td>country far moment theres turning back best ho...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new political party gave full front page ad po...</td>\n",
       "      <td>https://i.redd.it/yjo9wpy38el41.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>looks like iipm ad get funds full page ads use...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit backlash posts lack medical gear doctors g...</td>\n",
       "      <td>https://theprint.in/india/hit-by-backlash-over...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>well people really deserve die country fucking...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics time corona wb cm questions centres c...</td>\n",
       "      <td>https://www.timesnownews.com/india/article/pol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oh ffs yellow orange green red used emergency ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                             polite request indians   \n",
       "1   pitting community political party fucking stupid   \n",
       "2  new political party gave full front page ad po...   \n",
       "3  hit backlash posts lack medical gear doctors g...   \n",
       "4  politics time corona wb cm questions centres c...   \n",
       "\n",
       "                                                 Url  \\\n",
       "0  https://www.reddit.com/r/india/comments/g2ct57...   \n",
       "1  https://www.reddit.com/r/india/comments/futac9...   \n",
       "2                https://i.redd.it/yjo9wpy38el41.jpg   \n",
       "3  https://theprint.in/india/hit-by-backlash-over...   \n",
       "4  https://www.timesnownews.com/india/article/pol...   \n",
       "\n",
       "                                             Content  \\\n",
       "0  dont know situation countries india seen lot o...   \n",
       "1  first let start saying stupid whatever muslims...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Comments     Flair  \n",
       "0  society thrives abuse power let many idiots ab...  Politics  \n",
       "1  country far moment theres turning back best ho...  Politics  \n",
       "2  looks like iipm ad get funds full page ads use...  Politics  \n",
       "3  well people really deserve die country fucking...  Politics  \n",
       "4  oh ffs yellow orange green red used emergency ...  Politics  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Title\n",
    "dataset['Title'] = dataset['Title'].apply(transformText)\n",
    "\n",
    "# 2. Content\n",
    "#Since content contains NaN values, applying transformation to selected posts only\n",
    "dataset['Content'] = dataset['Content'].apply(lambda x: transformText(x) if(pd.notnull(x)) else x) \n",
    "dataset.head()\n",
    "\n",
    "# 3. Comments\n",
    "#since comments can also contain null, we use the same method as used for content\n",
    "dataset['Comments'] = dataset['Comments'].apply(lambda x: transformText(x) if(pd.notnull(x)) else x) \n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "    nb = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                ], verbose=True)\n",
    "    nb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svm(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    \n",
    "    svm = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', LinearSVC()),\n",
    "                ], verbose=True)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    log_reg = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', LogisticRegression()),\n",
    "                ], verbose=True)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    \n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forests(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    rf = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', RandomForestClassifier()),\n",
    "                ], verbose=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \n",
    "    mlp = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MLPClassifier()),\n",
    "                ], verbose=True)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = mlp.predict(X_test)\n",
    "    \n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size:  (1200,)\n",
      "Training dataset size:  (804,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.Title\n",
    "y = dataset.Flair\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Original dataset size: \", X.shape)\n",
    "print(\"Training dataset size: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dataset on the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "accuracy 0.6742424242424242\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.79      0.62      0.70        37\n",
      "  Business/Finance       0.39      0.41      0.40        32\n",
      "       CAA-NRC-NPR       0.75      0.90      0.82        30\n",
      "       Coronavirus       0.64      0.94      0.76        32\n",
      "              Food       0.75      0.83      0.79        36\n",
      "     Non-Political       0.50      0.86      0.63        28\n",
      "       Photography       0.78      0.85      0.81        33\n",
      "    Policy/Economy       0.64      0.43      0.52        37\n",
      "          Politics       0.78      0.51      0.62        35\n",
      "         Scheduled       0.71      0.48      0.58        31\n",
      "Science/Technology       0.63      0.59      0.61        32\n",
      "            Sports       0.86      0.73      0.79        33\n",
      "\n",
      "          accuracy                           0.67       396\n",
      "         macro avg       0.69      0.68      0.67       396\n",
      "      weighted avg       0.69      0.67      0.67       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "accuracy 0.7070707070707071\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.68      0.68      0.68        37\n",
      "  Business/Finance       0.35      0.50      0.41        32\n",
      "       CAA-NRC-NPR       0.84      0.87      0.85        30\n",
      "       Coronavirus       0.82      0.97      0.89        32\n",
      "              Food       0.82      0.89      0.85        36\n",
      "     Non-Political       0.82      0.82      0.82        28\n",
      "       Photography       0.85      0.85      0.85        33\n",
      "    Policy/Economy       0.62      0.49      0.55        37\n",
      "          Politics       0.81      0.60      0.69        35\n",
      "         Scheduled       0.53      0.52      0.52        31\n",
      "Science/Technology       0.74      0.62      0.68        32\n",
      "            Sports       0.75      0.73      0.74        33\n",
      "\n",
      "          accuracy                           0.71       396\n",
      "         macro avg       0.72      0.71      0.71       396\n",
      "      weighted avg       0.72      0.71      0.71       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_svm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "accuracy 0.7070707070707071\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.66      0.62      0.64        37\n",
      "  Business/Finance       0.31      0.56      0.40        32\n",
      "       CAA-NRC-NPR       0.90      0.90      0.90        30\n",
      "       Coronavirus       0.79      0.97      0.87        32\n",
      "              Food       0.84      0.86      0.85        36\n",
      "     Non-Political       0.92      0.82      0.87        28\n",
      "       Photography       0.87      0.79      0.83        33\n",
      "    Policy/Economy       0.64      0.43      0.52        37\n",
      "          Politics       0.85      0.63      0.72        35\n",
      "         Scheduled       0.56      0.58      0.57        31\n",
      "Science/Technology       0.79      0.59      0.68        32\n",
      "            Sports       0.76      0.79      0.78        33\n",
      "\n",
      "          accuracy                           0.71       396\n",
      "         macro avg       0.74      0.71      0.72       396\n",
      "      weighted avg       0.74      0.71      0.71       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "accuracy 0.7146464646464646\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.68      0.57      0.62        37\n",
      "  Business/Finance       0.32      0.62      0.42        32\n",
      "       CAA-NRC-NPR       0.90      0.87      0.88        30\n",
      "       Coronavirus       0.94      0.94      0.94        32\n",
      "              Food       0.86      0.89      0.88        36\n",
      "     Non-Political       0.92      0.79      0.85        28\n",
      "       Photography       0.81      0.88      0.84        33\n",
      "    Policy/Economy       0.58      0.49      0.53        37\n",
      "          Politics       0.85      0.66      0.74        35\n",
      "         Scheduled       0.67      0.52      0.58        31\n",
      "Science/Technology       0.83      0.59      0.69        32\n",
      "            Sports       0.69      0.82      0.75        33\n",
      "\n",
      "          accuracy                           0.71       396\n",
      "         macro avg       0.75      0.72      0.73       396\n",
      "      weighted avg       0.75      0.71      0.72       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "accuracy 0.5580808080808081\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.53      0.49      0.51        37\n",
      "  Business/Finance       0.21      0.25      0.23        32\n",
      "       CAA-NRC-NPR       0.75      0.80      0.77        30\n",
      "       Coronavirus       0.66      0.66      0.66        32\n",
      "              Food       0.64      0.69      0.67        36\n",
      "     Non-Political       0.62      0.57      0.59        28\n",
      "       Photography       0.76      0.76      0.76        33\n",
      "    Policy/Economy       0.48      0.41      0.44        37\n",
      "          Politics       0.52      0.49      0.50        35\n",
      "         Scheduled       0.37      0.52      0.43        31\n",
      "Science/Technology       0.67      0.56      0.61        32\n",
      "            Sports       0.67      0.55      0.60        33\n",
      "\n",
      "          accuracy                           0.56       396\n",
      "         macro avg       0.57      0.56      0.56       396\n",
      "      weighted avg       0.57      0.56      0.56       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
